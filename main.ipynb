{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import (\n",
    "    StringIndexer, OneHotEncoder, Imputer, VectorAssembler, StandardScaler\n",
    ")\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "@st.cache_resource()\n",
    "def get_spark_session() -> SparkSession:\n",
    "    \"\"\"\n",
    "    Crée (une seule fois) et retourne une session Spark optimisée.\n",
    "    \"\"\"\n",
    "    print(\"--- CRÉATION D'UNE NOUVELLE SESSION SPARK ---\")\n",
    "\n",
    "\n",
    "    # URL du master (local[*] pour le dev, ou URL du master Spark)\n",
    "    spark_master_url = os.environ.get(\"SPARK_MASTER_URL\", \"local[*]\")\n",
    "\n",
    "    # Configuration MongoDB\n",
    "    # Remplacez \"mongo\" par \"localhost\" si vous exécutez SANS Docker Compose\n",
    "    mongo_url = \"mongodb://mongo:27017/bank_attrition\"\n",
    "\n",
    "    return (\n",
    "        SparkSession.builder\n",
    "        .appName(\"AttritionPrediction\")\n",
    "        .master(spark_master_url)\n",
    "        .getOrCreate()\n",
    "    )\n",
    "spark = get_spark_session()\n",
    "st.title(\"Projet de Prédiction d'Attrition Client (PySpark, MLlib, MongoDB)\")\n",
    "\n",
    "st.header(\"Étape 1 : Configuration et Initialisation de Spark\")\n",
    "st.write(f\"Session Spark démarrée. Version : **{spark.version}**\")\n",
    "\n",
    "DATA_FILE = \"/app/datasets/DataCoSupplyChainDataset.csv\"\n",
    "def load_data(file_path):\n",
    "    \"\"\"Charge les données CSV dans un DataFrame Spark.\"\"\"\n",
    "    try:\n",
    "        return spark.read.csv(file_path, header=True, inferSchema=True, sep=',')\n",
    "    except Exception as e:\n",
    "        st.error(f\"Erreur lors du chargement du fichier {file_path}: {e}\")\n",
    "        st.error(\"Assurez-vous que le fichier 'data-set.csv' est présent dans le même répertoire.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "df = load_data(DATA_FILE)\n",
    "\n",
    "if df:\n",
    "    st.write(\"✅ Données brutes chargées avec succès.\")\n",
    "\n",
    "    st.write(\"Aperçu des 5 premières lignes :\")\n",
    "    st.dataframe(df.limit(5).toPandas())"
   ],
   "id": "c450a616b3df5792",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "    cols = [\n",
    "        # Variable Cible\n",
    "        'Late_delivery_risk',\n",
    "\n",
    "        'Days for shipment (scheduled)',\n",
    "        'order date (DateOrders)',\n",
    "        'Shipping Mode',\n",
    "        'Market',\n",
    "        'Order Region',\n",
    "        'Latitude',\n",
    "        'Longitude',\n",
    "        'Category Name',\n",
    "        'Department Name',\n",
    "        'Order Item Quantity',\n",
    "        'Product Status',\n",
    "        'Customer Segment',\n",
    "        'Order Item Total',\n",
    "        'Order Profit Per Order',\n",
    "        'Order Item Discount Rate'\n",
    "    ]\n",
    "    new_df = df.select(cols)\n",
    "    st.dataframe(new_df.limit(5).toPandas())"
   ],
   "id": "52f31681baabfdd1",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "    st.dataframe(new_df.select(\"Market\").distinct().toPandas())\n"
   ],
   "id": "ad2f235bd0588dc4",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "    st.dataframe(new_df.select(\"Late_delivery_risk\").distinct().toPandas())\n",
   "id": "500fc9d9e419c7d7",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "    st.dataframe(new_df.select(\"Category Name\").distinct().toPandas())\n",
   "id": "a93fd834e48d282b",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "    st.dataframe(new_df.select(\"Customer Segment\").distinct().toPandas())\n",
   "id": "7d87beff1383c5f",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "    st.dataframe(new_df.select(\"Market\").distinct().toPandas())\n",
   "id": "cbdc6187e316c1b1",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "    st.dataframe(new_df.select(\"Shipping Mode\").distinct().toPandas())\n",
   "id": "7317cc75ca57f689",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "    st.dataframe(new_df.select(\"Latitude\" , \"Longitude\").distinct().toPandas())\n",
   "id": "dd274323464568f1",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "    st.dataframe(new_df.distinct().toPandas())\n",
   "id": "52f95bcf87f3e8b7",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "    st.text(len(new_df.distinct().toPandas()) - len(new_df.toPandas()))\n",
   "id": "38f66405d1de3a44",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "    st.write(\"Schéma des colonnes :\")\n",
    "    # Capture du printSchema pour l'afficher dans Streamlit\n",
    "    from io import StringIO\n",
    "    import sys\n",
    "\n",
    "    old_stdout = sys.stdout\n",
    "    redirected_output = StringIO()\n",
    "    sys.stdout = redirected_output\n",
    "    new_df.printSchema()\n",
    "    sys.stdout = old_stdout\n",
    "\n",
    "    st.text(redirected_output.getvalue())"
   ],
   "id": "efd765371f83872b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
